{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a library for calculating some of the graph centrality measures. \n",
    "It can be used to compute the Degree, Closeness, Eigenvector, Katz, PageRank, and Betweenness centralities of a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import Graph\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class GraphCentralities:    \n",
    "    def adj_list_to_matrix(self, adj_list):\n",
    "        nodes = list(adj_list.keys())\n",
    "        n = len(nodes)\n",
    "        adj_matrix = [[0 for i in range(n)] for j in range(n)]\n",
    "        \n",
    "        for node in adj_list:\n",
    "            row_index = nodes.index(node)\n",
    "            # print(\"nodes values\", adj_list[node])\n",
    "            for neighbor in adj_list[node][1]:\n",
    "                col_index = nodes.index(neighbor[0])\n",
    "                adj_matrix[row_index][col_index] = 1\n",
    "                \n",
    "        return adj_matrix, nodes\n",
    "    \n",
    "    def degree_centrality(self, graph):\n",
    "        degree_centrality = {}\n",
    "        \n",
    "        # The degree of a node is the connections it has with other nodes. Which can be calculated easily from an adjacency list.\n",
    "        for node in graph:\n",
    "            degree = len(graph[node][1])\n",
    "\n",
    "            # Calculate the degree centrality for the current node\n",
    "            centrality = degree / (len(graph) - 1) if len(graph) > 1 else 0\n",
    "            degree_centrality[node] = centrality\n",
    "\n",
    "        maximum = max(degree_centrality.values())\n",
    "        top_ranked = []\n",
    "        for node, centrality in degree_centrality.items():\n",
    "            if centrality == maximum: \n",
    "                top_ranked.append(graph[node][0].data)\n",
    "                \n",
    "        return degree_centrality, top_ranked\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Calculate the shortest path distances between nodes using BFS\n",
    "    \n",
    "    # Compute the closeness centrality for each node\n",
    "    def closeness_centrality(self, graph):\n",
    "        def bfs_distances(graph, source):\n",
    "            # Initialize the distances dictionary with infinite distances for all nodes\n",
    "            distances = {node: float('inf') for node in graph}\n",
    "            distances[source] = 0 \n",
    "            # Use BFS to traverse the graph and update distances\n",
    "            queue = [source]\n",
    "            while queue:\n",
    "                curr_node = queue.pop(0)\n",
    "                for neighbor,cost in graph[curr_node][1]:\n",
    "                    total_dist= distances[curr_node] + cost\n",
    "                    if distances[neighbor] == float('inf'):\n",
    "                        distances[neighbor]=total_dist\n",
    "                        queue.append(neighbor)\n",
    "                    if distances[neighbor]>total_dist:\n",
    "                        distances[neighbor]=total_dist\n",
    "            \n",
    "            return distances\n",
    "        node_names=[node for node in graph]\n",
    "        closeness_scores = [0 for i in range(len(node_names))]\n",
    "        \n",
    "        close=0\n",
    "        for i in range(len(node_names)):\n",
    "            distances = bfs_distances(graph, node_names[i])\n",
    "            sum_distances = sum(distances.values())\n",
    "            closeness_scores[i] = (len(node_names) - 1) / sum_distances\n",
    "            if closeness_scores[i]>close:\n",
    "                close=closeness_scores[i]\n",
    "        top_ranked = []\n",
    "        maximum = max(closeness_scores)\n",
    "        for i in range(len(closeness_scores)):\n",
    "            if closeness_scores[i] == maximum:\n",
    "                top_ranked.append((node_names[i], closeness_scores[i]))\n",
    "                \n",
    "        return closeness_scores, top_ranked\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def eigenvector_centrality(self, graph, max_iter = 100, tol=1e-6):\n",
    "        \n",
    "        # Initialize centrality scores with equal weights\n",
    "        adjacency_matrix, nodes = self.adj_list_to_matrix(graph)\n",
    "        centrality = np.ones(len(adjacency_matrix))\n",
    "        centrality /= np.linalg.norm(centrality)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            new_centrality = np.dot(adjacency_matrix, centrality)\n",
    "\n",
    "            # Normalizing the centrality scores\n",
    "            new_centrality /= np.linalg.norm(new_centrality)\n",
    "\n",
    "            # Checking for convergence\n",
    "            if np.linalg.norm(new_centrality - centrality, 2) < tol:\n",
    "                break\n",
    "\n",
    "            centrality = new_centrality\n",
    "\n",
    "        maximum = max(centrality)\n",
    "        top_ranked = []\n",
    "        \n",
    "        for i in range(len(centrality)):\n",
    "            if centrality[i] == maximum:\n",
    "                top_ranked.append(nodes[i])\n",
    "                \n",
    "        return centrality, top_ranked\n",
    "\n",
    "    def katz_centrality(self, graph, alpha=0.1, beta=1.0, max_iter=100, tol=1e-6):\n",
    "        adjacency_matrix, nodes = self.adj_list_to_matrix(graph)\n",
    "        n = len(adjacency_matrix)\n",
    "        \n",
    "        # Initialize centrality scores\n",
    "        centrality = np.zeros(n)\n",
    "        beta = np.full(n, beta)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # Update centrality scores using the Katz centrality equation\n",
    "            new_centrality = alpha * np.dot(adjacency_matrix, centrality) + beta\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(new_centrality - centrality, 2) < tol:\n",
    "                break\n",
    "\n",
    "            centrality = new_centrality\n",
    "\n",
    "        centrality /= np.linalg.norm(centrality)\n",
    "        top_ranked = []\n",
    "        maximum = max(centrality)\n",
    "        for i in range(len(centrality)):\n",
    "            if centrality[i] == maximum:\n",
    "                top_ranked.append((nodes[i], centrality[i]))\n",
    "                \n",
    "        return centrality, top_ranked\n",
    "        \n",
    "\n",
    "    def pagerank(self, graph, d=0.85, max_iter=100, tolerance=1e-6):\n",
    "        adjacency_matrix, nodes = self.adj_list_to_matrix(graph)\n",
    "        # Convert the adjacency matrix to a NumPy array\n",
    "        adjacency_matrix = np.array(adjacency_matrix)\n",
    "\n",
    "        # Get the number of nodes in the graph\n",
    "        N = len(adjacency_matrix)\n",
    "\n",
    "        # Initialize PageRank scores with equal weights\n",
    "        pagerank_scores = np.ones(N) / N\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # Normalize the adjacency matrix to represent transition probabilities\n",
    "            row_sums = adjacency_matrix.sum(axis=1, keepdims=True)\n",
    "            transition_matrix = np.where(np.logical_and(row_sums != 0, ~np.isnan(row_sums), ~np.isnan(adjacency_matrix)), adjacency_matrix / row_sums, 1 / N)\n",
    "\n",
    "            # Calculate the next iteration of PageRank scores\n",
    "            new_pagerank_scores = (1 - d) / N + d * np.dot(transition_matrix.T, pagerank_scores)\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(new_pagerank_scores - pagerank_scores, 2) < tolerance:\n",
    "                break\n",
    "\n",
    "            pagerank_scores = new_pagerank_scores\n",
    "            \n",
    "        top_ranked = []\n",
    "        maximum = max(pagerank_scores)\n",
    "        for i in range(len(pagerank_scores)):\n",
    "            if pagerank_scores[i] == maximum:\n",
    "                top_ranked.append((nodes[i], pagerank_scores[i]))\n",
    "                \n",
    "\n",
    "        return pagerank_scores, top_ranked\n",
    "    \n",
    "    def betweenness_centrality(self, graph):\n",
    "        # initialize variables\n",
    "        betweenness = {node: 0.0 for node in graph}\n",
    "        \n",
    "        # loop over all nodes\n",
    "        for s in graph:\n",
    "            queue = deque()\n",
    "            stack = []\n",
    "            dist = {node: -1 for node in graph}\n",
    "            paths = {node: [] for node in graph}\n",
    "            sigma = {node: 0 for node in graph}\n",
    "            \n",
    "            dist[s] = 0\n",
    "            sigma[s] = 1\n",
    "            queue.append(s)\n",
    "            \n",
    "            while queue:\n",
    "                v = queue.popleft()\n",
    "                stack.append(v)\n",
    "                \n",
    "                for w, node in graph[v][1]:\n",
    "                    if dist[w] < 0:\n",
    "                        queue.append(w)\n",
    "                        dist[w] = dist[v] + 1\n",
    "                    \n",
    "                    if dist[w] == dist[v] + 1:\n",
    "                        sigma[w] += sigma[v]\n",
    "                        paths[w].append(v)\n",
    "            \n",
    "            delta = {node: 0 for node in graph}\n",
    "            while stack:\n",
    "                w = stack.pop()\n",
    "                for v in paths[w]:\n",
    "                    delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])\n",
    "                if w != s:\n",
    "                    betweenness[w] += delta[w]\n",
    "                    \n",
    "        max_between=max(betweenness.values())\n",
    "        top_ranked = []\n",
    "        for i in betweenness:\n",
    "            if betweenness[i]==max_between:\n",
    "                top_ranked.append((i,max_between))\n",
    "                \n",
    "        return betweenness, top_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Graph Centrality library with the graph of Romania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================ANSWER==========================\n",
      "top ranked by degree:  ['Sibiu', 'Bucharest']\n",
      "centrality computation: {'Oradea': 0.10526315789473684, 'Zerind': 0.10526315789473684, 'Arad': 0.15789473684210525, 'Timisoara': 0.10526315789473684, 'Lugoj': 0.10526315789473684, 'Mehadia': 0.10526315789473684, 'Drobeta': 0.10526315789473684, 'Craiova': 0.15789473684210525, 'Sibiu': 0.21052631578947367, 'Rimnicu_Vilcea': 0.15789473684210525, 'Fagaras': 0.10526315789473684, 'Pitesti': 0.15789473684210525, 'Giurgiu': 0.05263157894736842, 'Bucharest': 0.21052631578947367, 'Urziceni': 0.15789473684210525, 'Eforie': 0.05263157894736842, 'Hirsova': 0.10526315789473684, 'Vaslui': 0.10526315789473684, 'Iasi': 0.10526315789473684, 'Neamt': 0.05263157894736842}\n",
      "\n",
      "top ranked by closeness:  [('Pitesti', 0.0034289839379173436)]\n",
      "centrality computation: [0.0022700119474313024, 0.0021420518602029313, 0.0024771838331160367, 0.0021162842503898416, 0.0021687022029448695, 0.002287778446718844, 0.0024733142410830514, 0.002938447262604392, 0.0029190351820556153, 0.003294607248135946, 0.002819409407924024, 0.0034289839379173436, 0.0025242460475621096, 0.003216522769595395, 0.002884469409442842, 0.0019581572709471296, 0.0023298589822194973, 0.002215743440233236, 0.0018911117746591023, 0.0016360974769654697]\n",
      "\n",
      "top ranked by eigenvector:  ['Rimnicu_Vilcea']\n",
      "centrality computation: [0.19915817 0.15715493 0.23859534 0.10985086 0.06739319 0.0778707\n",
      " 0.14951453 0.33859819 0.39759392 0.40413334 0.26560569 0.38951121\n",
      " 0.12286714 0.34224313 0.17532858 0.02594044 0.07225634 0.07387344\n",
      " 0.03044486 0.01092981]\n",
      "\n",
      "top ranked by katz:  [('Sibiu', 0.26209313408459767)]\n",
      "centrality computation: [0.21754612 0.21545049 0.23904113 0.21495009 0.21254202 0.21255234\n",
      " 0.21506359 0.24016592 0.26209313 0.24444132 0.22198541 0.24423681\n",
      " 0.19577612 0.25984347 0.23851894 0.19106682 0.21275035 0.21467789\n",
      " 0.21034217 0.190826  ]\n",
      "\n",
      "top ranked by pagerank:  [('Bucharest', 0.08145625379364226)]\n",
      "centrality computation: [0.0413833  0.04207394 0.05995133 0.04368927 0.0451841  0.0449788\n",
      " 0.04300169 0.05783146 0.07530222 0.05605968 0.04081132 0.0570787\n",
      " 0.02480953 0.08145625 0.06829882 0.02960758 0.05201756 0.0503096\n",
      " 0.05519647 0.03095837]\n",
      "\n",
      "top ranked by betweenness:  [('Bucharest', 184.66666666666669)]\n",
      "centrality computation: {'Oradea': 13.666666666666666, 'Zerind': 3.6666666666666665, 'Arad': 65.33333333333333, 'Timisoara': 27.666666666666664, 'Lugoj': 13.666666666666668, 'Mehadia': 19.666666666666664, 'Drobeta': 39.0, 'Craiova': 62.33333333333333, 'Sibiu': 120.0, 'Rimnicu_Vilcea': 29.666666666666664, 'Fagaras': 88.0, 'Pitesti': 74.66666666666666, 'Giurgiu': 0.0, 'Bucharest': 184.66666666666669, 'Urziceni': 152.0, 'Eforie': 0.0, 'Hirsova': 36.0, 'Vaslui': 68.0, 'Iasi': 36.0, 'Neamt': 0.0}\n",
      "\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "from graph import Graph\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "romania = Graph()\n",
    "with open('cities.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        c = line.strip().split()\n",
    "        if c[0] == \"City\":\n",
    "            continue\n",
    "        romania.createNode(c[0], (float(c[1]), float(c[2])))\n",
    "\n",
    "with open('edges.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        c = line.strip().split()\n",
    "        romania.insertEdge(c[0], c[1], int(c[2]))\n",
    "\n",
    "def format_answer(ans, centrality):\n",
    "    computation, top_ranked = ans\n",
    "    print(f'top ranked by {centrality}: ', top_ranked)\n",
    "    print('centrality computation:', computation)\n",
    "    print(\"\")\n",
    "        \n",
    "gc = GraphCentralities()      \n",
    "graphs = [romania]\n",
    "\n",
    "for graph in graphs:\n",
    "    print(\"=====================ANSWER==========================\")\n",
    "    \n",
    "    format_answer(gc.degree_centrality(graph.adjacencyDic), \"degree\")\n",
    "    \n",
    "    format_answer(gc.closeness_centrality(graph.adjacencyDic), \"closeness\")\n",
    "    \n",
    "    format_answer(gc.eigenvector_centrality(graph.adjacencyDic), \"eigenvector\")\n",
    "    \n",
    "    format_answer(gc.katz_centrality(graph.adjacencyDic), \"katz\")\n",
    "    \n",
    "    format_answer(gc.pagerank(graph.adjacencyDic), \"pagerank\")\n",
    "    \n",
    "    format_answer(gc.betweenness_centrality(graph.adjacencyDic), \"betweenness\")\n",
    "       \n",
    "    print(\"=====================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
